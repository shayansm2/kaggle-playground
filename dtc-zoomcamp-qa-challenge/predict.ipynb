{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at model.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'For the project, how long will be the timeframe to complete it?'\n",
    "ans1 = \"Alexey\\nYou can just take a look at the thread with datasets that we had in Slack and I’m pretty sure you will find something interesting there. Then just go from there. I would start from a dataset. First, I would find the dataset and then try to think what exactly I can do with this dataset.\\nAnkush\\nI can say that if you finish one project where you are basically using more batch processing, then maybe the next project can be more real-time processing. Similarly if you're doing less Airflow, then do more Airflow. Something like that. Try to explore different areas to broaden your knowledge.\\nSejal\\nNothing else to add from my end, really. Basically just what you guys said. I think it really depends on the needs are. The situation is based on what you feel like learning, what you think is important for you to learn in order to implement, with respect to what you're currently working on. I think you'll figure it out. In addition to what you're learning in this course, maybe you could also try learning some standard software engineering skills on your own, which can be applied in data engineering as well, such as orchestrating CI/CD pipelines, workflows, GitOps, automated test cases, especially unit tests, maybe with pytest. You can use pytest in combination with Airflow. Make your code more production-friendly, basically. We haven't really covered that. I'm not sure if we will be covering these modules in the next iterations. If we find the time, then definitely we will add it as bonus lectures. This is also something you can try out.\"\n",
    "label1 = 0\n",
    "\n",
    "q2 = 'For hyperparameter tuning, should I be tuning using the full train and test dataset?'\n",
    "ans2 = \"Yes. If you're running on Windows, what you can do is first install WSL (Windows Subsystem for Linux) and then use it. The second thing you can do is just altboot and install Ubuntu on your computer. This way, you can keep Windows and then for, let's say, development work, you just go and use Linux. Then every time you don't know how to do something, you Google it. At least this is how I learned Linux. I think you will be able to learn it this way as well.\\xa0\\nWhat you can do is – you have a command line, so just try to do as much as possible without leaving the command line. For example, say In this is Ls. If you want to look inside some file, you use “less”. Get familiar with tools like these simple Unix tools, like ls, less, CD, vd and so on – things like this. I think that should be sufficient for most of your work.\"\n",
    "label2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = tokenizer([q1, ans1], padding=True, truncation=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[ 0.11217336, -0.05528412],\n",
      "       [ 0.4276673 , -0.45240375]], dtype=float32)>, hidden_states=None, attentions=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model(**tokens1))\n",
    "np.argmax(model(**tokens1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
