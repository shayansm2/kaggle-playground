{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# model selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97fd4e3a10d8bee5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## import libs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82a7cd36083b86ea"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from abc import ABC\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:39:13.437972Z",
     "start_time": "2023-11-03T08:39:13.126251Z"
    }
   },
   "id": "4a32537bf2d27f03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "What we want to do here is to try various models in these data sets, train them and validate the results based on multiple metrics. We also want to play with model inputs to check its result. We also need to tune model hyperparameters. As we are going to train and test the model multiple times with different configs, it would be beneficial to prepare some code in advance in order to prevent rewriting code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "837e8faf82aad329"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train, validation and test data sets split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a55fbe3c7ab8b6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:39:14.951067Z",
     "start_time": "2023-11-03T08:39:14.926601Z"
    }
   },
   "id": "abb03d8f9d04ee5b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state_seed = 22\n",
    "df_train_validation, df_test = train_test_split(df, test_size=0.2, random_state=random_state_seed)\n",
    "df_train, df_validation = train_test_split(df_train_validation, test_size=0.25, random_state=random_state_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:39:15.404780Z",
     "start_time": "2023-11-03T08:39:15.375370Z"
    }
   },
   "id": "105b31bd3af749b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### converting data frame to desired input of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7780ccf4da6cea8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class InputProvider(object):\n",
    "    def get_train_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        pass\n",
    "\n",
    "    def get_test_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:39:17.206637Z",
     "start_time": "2023-11-03T08:39:17.179793Z"
    }
   },
   "id": "5b4e74fa549f6c6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_clean_text(mess: str):\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    nopunc = nopunc.lower().strip()\n",
    "\n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english')])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:39:17.857903Z",
     "start_time": "2023-11-03T08:39:17.835051Z"
    }
   },
   "id": "ad825f408389cf4d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def add_new_features_from_text(df_original: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_original.copy()\n",
    "    df['words_count'] = df.text.apply(len)\n",
    "\n",
    "    df['has_location'] = df['location'].notnull().astype(int)\n",
    "    del df['location']\n",
    "    df['has_question_mark'] = df['text'].str.contains('\\?').astype(int)\n",
    "    df['has_exclamation_mark'] = df['text'].str.contains('\\!').astype(int)\n",
    "    df['has_hashtag'] = df['text'].str.contains('\\#').astype(int)\n",
    "    df['has_capital_words'] = df['text'].apply(lambda x: str(x).isupper()).astype(int)\n",
    "    df['has_link'] = df['text'].str.contains(\n",
    "        'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+').astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_clean_text_features(df_original: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df_original.copy()\n",
    "    df['clean_text'] = df['text'].apply(get_clean_text)\n",
    "    df['clean_words_count'] = df['clean_text'].apply(len)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:40:11.695552Z",
     "start_time": "2023-11-03T08:40:11.658527Z"
    }
   },
   "id": "ff6170ea476d8d83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "InputProvider1 feature list:\n",
    "- words_count\n",
    "- has_location\n",
    "- has_question_mark\n",
    "- has_exclamation_mark\n",
    "- has_hashtag\n",
    "- has_capital_words\n",
    "- has_link\n",
    "\n",
    "dimension input matrix: n_rows * 7"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "670c04c69a79bd89"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class InputProvider1(InputProvider):\n",
    "    @staticmethod\n",
    "    def _get_input_base(df: pd.DataFrame) -> tuple:\n",
    "        df = add_new_features_from_text(df)\n",
    "        y = df.target\n",
    "        df.drop(columns=['id', 'text', 'keyword', 'target'], inplace=True)\n",
    "        x = df.values\n",
    "        return x, y\n",
    "\n",
    "    def get_train_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        return self._get_input_base(df)\n",
    "\n",
    "    def get_test_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        return self._get_input_base(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:40:35.150644Z",
     "start_time": "2023-11-03T08:40:35.120745Z"
    }
   },
   "id": "abba2e08fb5dedd1"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(4567, 7)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(InputProvider1().get_train_inputs(df_train)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:41:00.891009Z",
     "start_time": "2023-11-03T08:41:00.887831Z"
    }
   },
   "id": "ac448ac6a9f6f208"
  },
  {
   "cell_type": "markdown",
   "source": [
    "InputProvider2 feature list:\n",
    "- words_count\n",
    "- has_location\n",
    "- has_question_mark\n",
    "- has_exclamation_mark\n",
    "- has_hashtag\n",
    "- has_capital_words\n",
    "- has_link\n",
    "- keywords **(one hot encoding)** \n",
    "\n",
    "dimension input matrix: n_rows * 229"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a49f37e7ec038c5e"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "class InputProvider2(InputProvider):\n",
    "    def __init__(self):\n",
    "        self.vect = DictVectorizer()\n",
    "\n",
    "    def get_train_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        df = add_new_features_from_text(df)\n",
    "        y = df.target\n",
    "        df.drop(columns=['id', 'text', 'target'], inplace=True)\n",
    "        self.vect.fit(df.to_dict(orient='records'))\n",
    "        x = self.vect.transform(df.to_dict(orient='records'))\n",
    "        return x, y\n",
    "\n",
    "    def get_test_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        df = add_new_features_from_text(df)\n",
    "        y = df.target\n",
    "        df.drop(columns=['id', 'text', 'target'], inplace=True)\n",
    "        x = self.vect.transform(df.to_dict(orient='records'))\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:43:15.341551Z",
     "start_time": "2023-11-03T08:43:15.324117Z"
    }
   },
   "id": "eee3c29774acf2e2"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(4567, 229)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(InputProvider2().get_train_inputs(df_train)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:43:15.893336Z",
     "start_time": "2023-11-03T08:43:15.879659Z"
    }
   },
   "id": "f635fa8d2c9f90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "InputProvider3 feature list:\n",
    "- words_count\n",
    "- has_location\n",
    "- has_question_mark\n",
    "- has_exclamation_mark\n",
    "- has_hashtag\n",
    "- has_capital_words\n",
    "- has_link\n",
    "- clean text tokens \n",
    "\n",
    "dimension input matrix: n_rows * 229"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef6702ff05c90454"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "class InputProvider3(InputProvider):\n",
    "    def __init__(self):\n",
    "        self.vect = CountVectorizer()\n",
    "\n",
    "    def get_train_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        df = add_clean_text_features(add_new_features_from_text(df))\n",
    "        df.drop(columns=['id', 'text', 'target'], inplace=True)\n",
    "        y = df.target\n",
    "        self.vect.fit(df['clean_text'])\n",
    "        representation = self.vect.transform(df['clean_text']).toarray()\n",
    "\n",
    "    def get_test_inputs(self, df: pd.DataFrame) -> tuple:\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T08:19:48.109814Z"
    }
   },
   "id": "bf89a6dcb52d1193"
  },
  {
   "cell_type": "markdown",
   "source": [
    "InputProvider4 feature list:\n",
    "- words_count\n",
    "- has_location\n",
    "- has_question_mark\n",
    "- has_exclamation_mark\n",
    "- has_hashtag\n",
    "- has_capital_words\n",
    "- has_link\n",
    "- keywords **(one hot encoding)**\n",
    "- clean text tokens \n",
    "\n",
    "dimension input matrix: n_rows * 229"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d1e26ca68768045"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['crashed', 119, 1, ..., 1, 0, 0],\n       ['crash', 109, 1, ..., 0, 0, 1],\n       ['rescuers', 140, 1, ..., 0, 0, 1],\n       ...,\n       ['war%20zone', 31, 1, ..., 0, 0, 0],\n       ['refugees', 101, 1, ..., 1, 0, 1],\n       ['ambulance', 64, 0, ..., 0, 0, 0]], dtype=object)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, roc_curve, confusion_matrix, \\\n",
    "    ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "class MetricsCalculator(object):\n",
    "    def __init__(self, y_actual, y_probabilities):\n",
    "        self.y_true = y_actual\n",
    "        self.y_pred = y_probabilities\n",
    "\n",
    "    def get_auc(self):\n",
    "        return roc_auc_score(self.y_true, self.y_pred)\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        return accuracy_score(self.y_true, self.y_pred)\n",
    "\n",
    "    def get_recall(self):\n",
    "        return recall_score(self.y_true, self.y_pred)\n",
    "\n",
    "    def get_precision(self):\n",
    "        return precision_score(self.y_true, self.y_pred)\n",
    "\n",
    "    def get_confusion_matrix(self):\n",
    "        confusion_matrix(self.y_true, self.y_pred)\n",
    "\n",
    "    def show_confusion_matrix(self):\n",
    "        ConfusionMatrixDisplay(self.get_confusion_matrix()).plot()\n",
    "        plt.show()\n",
    "\n",
    "    def show_roc_curve(self):\n",
    "        fpr, tpr, _ = roc_curve(self.y_true, self.y_pred)\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0, 1], [0, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:21:11.853961Z",
     "start_time": "2023-11-03T08:21:11.838080Z"
    }
   },
   "id": "5970d368ca709941"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['crashed', 119, 1, ..., 1, 0, 0],\n       ['crash', 109, 1, ..., 0, 0, 1],\n       ['rescuers', 140, 1, ..., 0, 0, 1],\n       ...,\n       ['war%20zone', 31, 1, ..., 0, 0, 0],\n       ['refugees', 101, 1, ..., 1, 0, 1],\n       ['ambulance', 64, 0, ..., 0, 0, 0]], dtype=object)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import abc\n",
    "\n",
    "\n",
    "class ModelInterface:\n",
    "    @abc.abstractmethod\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T08:21:42.925075Z",
     "start_time": "2023-11-03T08:21:42.906014Z"
    }
   },
   "id": "98c4c43c43f27efa"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class TrainValidationWorkflow(object):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: ModelInterface,\n",
    "            input_provider: InputProvider,\n",
    "            df_train: pd.DataFrame,\n",
    "            df_validation: pd.DataFrame = None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.input_provider = input_provider\n",
    "        self.df_train = df_train\n",
    "        self.df_validation = df_validation\n",
    "\n",
    "    def get_model(self):\n",
    "        self._train_flow()\n",
    "        return self.model\n",
    "\n",
    "    def get_metrics_calculator(self) -> MetricsCalculator:\n",
    "        self._train_flow()\n",
    "        assert self.df_validation is not None, 'you should provide the validation dataframe'\n",
    "        x_validation, y_validation = self.input_provider.get_test_inputs(self.df_validation)\n",
    "        return MetricsCalculator(y_validation, self.model.predict_proba(x_validation))\n",
    "\n",
    "    def _train_flow(self):\n",
    "        x_train, y_train = self.input_provider.get_train_inputs(self.df_train)\n",
    "        self.model.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T07:41:58.526207Z"
    }
   },
   "id": "f68b7b44431fe127"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2f80dfd77102e00"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a271dea3c4e81661"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrmodel = LogisticRegression()\n",
    "lrflow = TrainValidationWorkflow(model=lrmodel, input_provider=None, df_train=df_train, df_validation=df_validation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bac8ceedab413c9f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
